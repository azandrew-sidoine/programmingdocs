{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('./Tiny_Faces_in_Tensorflow/')\n",
    "#import tiny_face_eval as tiny\n",
    "import evaluate\n",
    "from metrics import *\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import imp\n",
    "import time\n",
    "import random\n",
    "import detect\n",
    "import dlib\n",
    "from imgaug import augmenters as iaa\n",
    "#imp.reload(tiny)\n",
    "imp.reload(detect)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = './Tiny_Faces_in_Tensorflow/hr_res101.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/home/alexattia/Work/RecVis/famvk.avi')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "initial_target = int(45 * fps) + 10\n",
    "final_target = int(49 * fps) + 10\n",
    "i = 0\n",
    "frames = []\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    i +=1 \n",
    "    if i in range(initial_target, final_target+10):\n",
    "        frames.append(frame[:,:,::-1])\n",
    "    if i == final_target:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for k in range(0, len(frames), 10):\n",
    "    try:\n",
    "        imgs = [frames[k], frames[k+1], frames[k+2], frames[k+10]]\n",
    "    except IndexError:\n",
    "        imgs = [frames[k], frames[k+1], frames[k+2], frames[len(frames)-1]]\n",
    "    images.append(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_detections = []\n",
    "for frames in images:\n",
    "    detections = []\n",
    "    for frame in frames:\n",
    "        with tf.Graph().as_default():\n",
    "            b = evaluate.evaluate(weight_file_path=weights_path,  img=frame)\n",
    "        detections.append(b)\n",
    "    all_detections.append(detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 15.8 sec i.e 0.25/detection\n",
      "It took 16.8 sec i.e 0.27/detection\n",
      "It took 19.1 sec i.e 0.27/detection\n",
      "It took 18.6 sec i.e 0.26/detection\n",
      "It took 17.7 sec i.e 0.26/detection\n",
      "It took 17.6 sec i.e 0.24/detection\n",
      "It took 18.8 sec i.e 0.26/detection\n",
      "It took 22.0 sec i.e 0.27/detection\n",
      "It took 24.5 sec i.e 0.28/detection\n",
      "It took 25.3 sec i.e 0.28/detection\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-20286546892d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'It took %.1f sec i.e %.2f/detection'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0bis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0bis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total : %.1f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "threshold = 0.55\n",
    "matcheds = []\n",
    "t0 = time.time()\n",
    "for j in range(len(images)):\n",
    "    frames = images[j]\n",
    "    detections = all_detections[j]\n",
    "    matched = 0\n",
    "    t0bis = time.time()\n",
    "    for p in range(len(detections[0])):\n",
    "        neigh_detect, distances = detect.train_binclas(frames, detections, p)\n",
    "        idx_max, val_max = np.argmax(distances[:,1]), np.max(distances[:,1])\n",
    "        if val_max > threshold:\n",
    "            matched += 1\n",
    "    matcheds.append(matched)\n",
    "    t1 = time.time()\n",
    "    print('It took %.1f sec i.e %.2f/detection' % (t1-t0bis, (t1-t0bis)/len(detections[0])))\n",
    "print('Total : %.1f' % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for j in range(10):\n",
    "    detections = all_detections[j]\n",
    "    s += len(detections[0]) - matcheds[j]\n",
    "s += len(detections[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gif Producting with counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/home/alexattia/Work/RecVis/famvk.avi')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "initial_target = int(45 * fps) + 10\n",
    "final_target = int(49 * fps) + 10\n",
    "i = 0\n",
    "frames = []\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    i +=1 \n",
    "    if i in range(initial_target, final_target, 1):\n",
    "        frames.append(frame[:,:,::-1])\n",
    "    if i == final_target:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = []\n",
    "for i, frame in enumerate(frames):\n",
    "    with tf.Graph().as_default():\n",
    "        b = tiny.evaluate(weight_file_path=weights_path, data_dir='.jpg', output_dir='', framee=frame,\n",
    "                          prob_thresh=0.5, nms_thresh=0.1, lw=3, \n",
    "                          display=False, save=False, draw=False, print_=0)\n",
    "    detections.append(b[0])\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing incremental count\n",
    "nbs = []\n",
    "init = len(all_detections[0][0])\n",
    "for j in range(1, 10):\n",
    "    nbs.append(init)\n",
    "    detections_ = all_detections[j]\n",
    "    init += len(detections_[0]) - matcheds[j-1]\n",
    "init += len(detections_[3]) - matcheds[j]\n",
    "nbs.append(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "l = 0\n",
    "images = []\n",
    "ff = []\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "for j, frame in enumerate(frames):\n",
    "    img = frame.copy()\n",
    "    for detect_ in detections[j]:\n",
    "        pt1, pt2 = tuple(detect_[:2]), tuple(detect_[2:])\n",
    "        cv2.rectangle(img, pt1, pt2, (255, 0, 0), 2)\n",
    "    cv2.putText(img, 'Incremental count : %d' % nbs[l], (1750,1300), font, 1.5, (0, 255, 0), 3)\n",
    "    if j in range(10, 89, 9):\n",
    "        l += 1\n",
    "    images.append(img)   \n",
    "    cv2.imwrite('./output_video/frames_%05d.png' % j, img[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gif Production without counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/home/alexattia/Work/RecVis/famvk.avi')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "initial_target = int(45 * fps) + 10\n",
    "final_target = int(49 * fps) + 10\n",
    "i = 0\n",
    "frames = []\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    i +=1 \n",
    "    if i in range(initial_target, final_target, 1):\n",
    "        frames.append(frame[:,:,::-1])\n",
    "    if i == final_target:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = []\n",
    "for i, frame in enumerate(frames):\n",
    "    with tf.Graph().as_default():\n",
    "        b = tiny.evaluate(weight_file_path=weights_path, data_dir='.jpg', output_dir='', framee=frame,\n",
    "                          prob_thresh=0.5, nms_thresh=0.1, lw=3, \n",
    "                          display=False, save=False, draw=False, print_=0)\n",
    "    detections.append(b[0])\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "images = []\n",
    "for j, frame in enumerate(frames):\n",
    "    img = frame.copy()\n",
    "    for detect_ in detections[k]:\n",
    "        pt1, pt2 = tuple(detect_[:2]), tuple(detect_[2:])\n",
    "        cv2.rectangle(img, pt1, pt2, (255, 0, 0), 2)\n",
    "    images.append(img)\n",
    "    if j in range(0, 94, 2):\n",
    "        k += 1\n",
    "    cv2.imwrite('./output_video/frame_%05d.png' % j, img[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
